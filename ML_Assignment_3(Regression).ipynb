{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062f18bb-1df8-436d-a68e-643362fee166",
   "metadata": {},
   "source": [
    "## **Theory Questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b05e4125-374d-49cf-854b-5f88c06668ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. What is Simple Linear Regression \n",
    "\n",
    "#ans.>> smiple linear regression(SLR) attempts to dermine the strengths and characterstics of the relationship between one independent variable(x)\n",
    "#        and another dependent variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba713cdc-a2ea-4201-bce7-5cb195804c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.What are the key assumptions of Simple Linear Regression \n",
    "\n",
    "#ans.>> key assumptions of Simple Linear Regression are :-\n",
    "#        1. there are only two varibales X and Y\n",
    "#        2. there is only two variable one is independent(X) and another is dependent variable(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762ce19-b8b6-41b0-8a30-7cb396cce4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. What does the coefficient m represent in the equation Y=mX+c \n",
    "\n",
    "#ans.>> m is the slope – it indicates the change in Y for a one-unit increase in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d759d722-4617-41a9-9db8-52fa45c33944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. What does the intercept c represent in the equation Y=mX+c \n",
    "\n",
    "#ans.>> c is the intercept – the value of Y when X = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7e30a-8923-456d-8f10-d5b8fd29e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. How do we calculate the slope m in Simple Linear Regression \n",
    "\n",
    "#ans.>> m = (y2 - y1)/(x2 - x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2e378-2b40-44f6-a5c5-3c904d53782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. What is the purpose of the least squares method in Simple Linear Regression \n",
    "\n",
    "#ans.>>To minimize the sum of squared differences between actual and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c64c261-9d90-4626-bb9a-1b5c211a3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression \n",
    "\n",
    "#ans.>> R² shows the proportion of variance in Y explained by X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09333a-bbf3-4cf8-a845-41dde7482c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. What is Multiple Linear Regression \n",
    "\n",
    "#ans.>>It models the relationship between one dependent variable and two or more independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9603f-abbb-4a25-b3dc-3d183ee24544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. What is the main difference between Simple and Multiple Linear Regression \n",
    "\n",
    "#ans.>> Simple linear regression: 1 independent variable\n",
    "#       Multiple linear regression: 2 or more independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f830d2ea-c968-48b0-bfab-54500731a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. What are the key assumptions of Multiple Linear Regression \n",
    "\n",
    "#ans.>> these are the key assumptions of Multiple Linear Regression :-\n",
    "#        1.Linearity\n",
    "#        2.Independence\n",
    "#        3.Homoscedasticity\n",
    "#        4.Normality\n",
    "#        5.No multicollinearity among independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c7f47-f0d9-47e0-bec5-e579b3f20d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model \n",
    "\n",
    "#ans.>>Unequal variance of residuals across the range of X values.\n",
    "#      It violates model assumptions and can lead to inefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c9910-95e3-458e-8f11-38a5abb64bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. How can you improve a Multiple Linear Regression model with high multicollinearity \n",
    "\n",
    "#ans.>> how we improve a Multiple Linear Regression model with high multicollinearity :-\n",
    "#        1.emove highly correlated predictors\n",
    "#        2.Use PCA (Principal Component Analysis)\n",
    "#        3.Apply Ridge or Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e5ff23-ea98-4bba-8b22-030b4bd2e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. What are some common techniques for transforming categorical variables for use in regression models \n",
    "\n",
    "#ans.>> these are some common techniques for transforming categorical variables for use in regression models \n",
    "#          1.one-hot-Encoding\n",
    "#          2.Label Encoder\n",
    "#          3. ordinal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b85f14f3-f102-48b9-b206-a1dc938333c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14. What is the role of interaction terms in Multiple Linear Regression \n",
    "\n",
    "#ans.>>Interaction terms (e.g., X₁×X₂) capture combined effects of variables that aren’t apparent individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8941d96-2b2d-4b7c-8b1d-506a86b907bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression \n",
    "\n",
    "#ans.>> Simple linear regression: Y when X = 0\n",
    "#       Multiple linear regression: Y when all X₁, X₂,… = 0 (may or may not have real-world meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43c1f5bd-60de-495f-9235-e06cbfebec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16. What is the significance of the slope in regression analysis, and how does it affect predictions\n",
    "\n",
    "#ans.>>Shows the effect of one unit change in X on Y. A larger slope implies a stronger relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b329693-1a36-4eb4-82c1-dc975d6c1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17. How does the intercept in a regression model provide context for the relationship between variables \n",
    "\n",
    "#ans.>>Provides a baseline value of Y when all predictors are zero. Important for understanding the starting point of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32133db0-cf87-4e22-939d-8de89828b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18. What are the limitations of using R² as a sole measure of model performance\n",
    "\n",
    "#ans.>> these are the limitations of using R² as a sole measure of model performance :-\n",
    "#        1.Doesn’t indicate if model is appropriate.\n",
    "#        2.Increases with more variables (even irrelevant ones).\n",
    "#        3.Doesn’t detect overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7db1857d-a39d-4bfe-a1b7-300286c87f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19. How would you interpret a large standard error for a regression coefficient \n",
    "\n",
    "#ans.>>Indicates uncertainty in the estimate; the variable might not significantly affect the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f58b5976-e136-4a2a-8a4b-fc81f30216ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20. What is polynomial regression When is polynomial regression used \n",
    "\n",
    "#ans.>>Polynomial regression fits a non-linear relationship using polynomial terms:\n",
    " #     Used when data shows other than a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e957ef-a71e-4eab-a4e6-15b92ff91beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21. How can heteroscedasticity be identified in residual plots, and why is it important to address it \n",
    "\n",
    "#ans.>>In residual plots: look for funnel-shaped patterns instead of randomness. Important to correct for valid inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913bbaa4-6b53-4c18-a248-b4149b02078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²\n",
    "\n",
    "#ans.>>Indicates the model includes irrelevant variables that don’t improve the model’s actual explanatory power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13871a31-029e-4c3e-a3aa-f5335b4941d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23. Why is it important to scale variables in Multiple Linear Regression \n",
    "\n",
    "#ans.>>  important to scale variables in Multiple Linear Regression \n",
    "#          1.Prevents bias due to different units\n",
    "#          2.Helps with convergence in optimization\n",
    "#          3.Especially important for regularization techniques (Ridge, Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c24ac430-3eed-422b-9576-fb45fbfddc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24. What is polynomial regression\n",
    "\n",
    "#ans.>>Polynomial regression fits a non-linear relationship using polynomial terms:\n",
    " #     Used when data shows other than a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1942372-8e0f-48c6-bf26-50b870e1f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25. How does polynomial regression differ from linear regression \n",
    "\n",
    "#ans.>> this is how polynomial regression differ from linear regression :-\n",
    "#          Linear regression: straight-line relationship\n",
    "#          Polynomial regression: allows curved trends using powers of the independent variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18ed7f4c-169a-4df8-b7b6-1dcdd65d8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#26. What is the general equation for polynomial regression\n",
    "\n",
    "#ans.>> y pred. = b0 + b1X + b2X**2 + b3X**3......bnX**n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5ac4359-f9d1-491c-9360-0eb8b58c878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#27. Can polynomial regression be applied to multiple variables \n",
    "\n",
    "#ans.>> Yes, called Multivariate Polynomial Regression, but complexity and risk of overfitting increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3f76e17-df5c-4dba-8a25-a2bc64971e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#28. What are the limitations of polynomial regression \n",
    "\n",
    "#ans.>> these are the limitations of polynomial regression :-\n",
    "#          1.Risk of overfitting\n",
    "#          2.Sensitive to outliers\n",
    "#          3.Not interpretable for high-degree polynomials\n",
    "#          4.May require scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f090d8e-8e50-47d7-b6e8-3f0be3224a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#29. What methods can be used to evaluate model fit when selecting the degree of a polynomial \n",
    "\n",
    "#ans.>> these are the methods can be used to evaluate model fit when selecting the degree of a polynomial \n",
    "#         1.Cross-validation\n",
    "#         2.Adjusted R²\n",
    "#         3.AIC/BIC\n",
    "#         4.Residual plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5522e188-227c-44ed-9202-85b33a29482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#30. Why is visualization important in polynomial regression \n",
    "\n",
    "#ans.>> 1.Helps in choosing the right degree of the polynomial\n",
    "#       2.Shows if model overfits or underfits\n",
    "#       3.Useful in communicating model behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "905ea4a2-9e42-4254-969a-1e4f4661e576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.2]\n"
     ]
    }
   ],
   "source": [
    "#31. How is polynomial regression implemented in Python?\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Sample data\n",
    "X = [[1], [2], [3], [4], [5]]\n",
    "y = [1.2, 1.9, 3.2, 3.8, 5.1]\n",
    "\n",
    "# Create a pipeline with degree 2 polynomial\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "pred = model.predict([[6]])\n",
    "print(pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
